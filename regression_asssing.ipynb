{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69962657-5402-4f08-81ed-7f9028d4c733",
   "metadata": {},
   "source": [
    "# Question-No.1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24cb5daf-8784-4889-a5ee-37e54cbc5bb9",
   "metadata": {},
   "source": [
    "Simple Linear Regression:-\n",
    "-> In simple linear regression, there is only one independent variable predicting the dependent variable.\n",
    "-> The relationship between the independent variable and the dependent variable is assumed to be linear.\n",
    "-> The regression equation takes the form: y = mx + c ;  where y is depenmdent variables , x is independent variable , c is intercept and m is slope coefficient.\n",
    "\n",
    "Multiple Linear Regression:\n",
    "\n",
    "-> In multiple linear regression, there are two or more independent variables predicting the dependent variable.\n",
    "-> The relationship between the independent variables and the dependent variable can be linear or nonlinear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c3b04-0c23-4ba4-8633-3f478a965495",
   "metadata": {},
   "source": [
    "# Question-No.2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "066f5f1a-998f-4c05-9644-941e8f295543",
   "metadata": {},
   "source": [
    "Linear regression relies on several assumptions to ensure the validity of the model estimates and predictions. These assumptions are:\n",
    "\n",
    "1- Linearity: The relationship between the independent variables and the dependent variable is linear. This means that changes in the independent variables result in proportional changes in the dependent variable.\n",
    "\n",
    "2- Independence of errors: The errors (residuals) should be independent of each other. There should be no systematic pattern in the residuals, and the error terms for any pair of observations should not be correlated.\n",
    "\n",
    "3- Homoscedasticity: The variance of the errors should be constant across all levels of the independent variables. In other words, the spread of the residuals should be consistent along the range of the predicted values.\n",
    "\n",
    "4- Normality of errors: The errors should follow a normal distribution. This assumption is about the distribution of the residuals, not necessarily the independent and dependent variables themselves.\n",
    "\n",
    "5- No perfect multicollinearity: In multiple linear regression, the independent variables should not be perfectly correlated with each other. High correlation between independent variables can lead to unstable estimates of the regression coefficients.\n",
    "\n",
    "To check whether these assumptions hold in a given dataset, various diagnostic tools and techniques can be used:\n",
    "\n",
    "1- Residual plots: Plot the residuals (the differences between the observed and predicted values) against the predicted values or against each independent variable. Patterns in the residual plots can indicate violations of the assumptions.\n",
    "\n",
    "2- Normality tests: Conduct statistical tests, such as the Shapiro-Wilk test or visual inspections like Q-Q plots, to assess whether the residuals follow a normal distribution.\n",
    "\n",
    "3- Homoscedasticity tests: Use statistical tests like the Breusch-Pagan test or White test to formally check for homoscedasticity. Additionally, plot residuals against fitted values and look for patterns or unequal spreads.\n",
    "\n",
    "4- Correlation matrix: Calculate the correlation matrix of the independent variables to check for multicollinearity. Correlation values close to 1 or -1 indicate strong correlations that may violate the assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd451d8a-0ae6-4a4a-888f-6e34eae59c28",
   "metadata": {},
   "source": [
    "# Question-No.3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04089858-17aa-4ab3-be64-e5d85840cd35",
   "metadata": {},
   "source": [
    "In a linear regression model, the slope and intercept represent the relationship between the independent variable(s) and the dependent variable.\n",
    "\n",
    "Intercept (β0): The intercept represents the value of the dependent variable when all independent variables are zero. It is the predicted value of the dependent variable when the independent variable(s) have no effect.\n",
    "\n",
    "Slope (β1): The slope represents the change in the dependent variable for a one-unit change in the independent variable(s). It indicates the rate of change of the dependent variable relative to changes in the independent variable(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b964a-84d0-4004-9fb4-ef8ea9d43281",
   "metadata": {},
   "source": [
    "# Question-No.4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a15ffa5b-548e-4646-b2f3-944aa9b420ac",
   "metadata": {},
   "source": [
    "Gradient descent-- Gradient descent is an optimization algorithm used to minimize the cost function of a model by iteratively updating the model's parameters in the direction of the steepest descent of the cost function. It is widely used in machine learning for training models, particularly in scenarios where the cost function is differentiable and convex or concave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccfbacd-d4d0-49b2-86d0-2d7864fe6e67",
   "metadata": {},
   "source": [
    "# Question-No.5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e106ee8d-d299-4ec5-86e8-1d32c531bde6",
   "metadata": {},
   "source": [
    "-> Multiple linear regression is an extension of simple linear regression that allows for the modeling of relationships between a dependent variable and multiple independent variables. In multiple linear regression, the dependent variable.\n",
    "\n",
    "-> Multiple Linear Regression is one of the important regression algorithms which models the linear relationship between a single dependent continuous variable and more than one independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac93a0-b302-49b9-b599-70ebb4c4e6fa",
   "metadata": {},
   "source": [
    "# Question-No.6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b0bd4f8-adbc-4512-ad33-b3d963f5bfde",
   "metadata": {},
   "source": [
    "Polynomial regression- Polynomial regression is a form of regression analysis that models the relationship between the independent variable(s) and the dependent variable as an nth-degree polynomial. Unlike linear regression, which assumes a linear relationship between the variables, polynomial regression can capture nonlinear relationships between the variables.\n",
    "\n",
    "Differences between polynomial regression and linear regression:\n",
    "\n",
    "Nature of Relationship:\n",
    "Polynomial regression can model nonlinear relationships between the independent and dependent variables, while linear regression assumes a linear relationship.\n",
    "\n",
    "Model Complexity:\n",
    "Polynomial regression can capture more complex patterns and curves in the data compared to linear regression, which is limited to straight lines.\n",
    "\n",
    "Number of Parameters:\n",
    "In polynomial regression, the number of parameters (coefficients) increases with the degree of the polynomial. For example, a quadratic polynomial (degree 2) has three parameters (intercept, coefficient for \n",
    "\n",
    "Overfitting:\n",
    "Polynomial regression with high-degree polynomials can be prone to overfitting, especially with limited data. Regularization techniques such as Ridge Regression or Lasso Regression are often used to mitigate overfitting in polynomial regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317cd50-b85d-4874-980e-a78f6907d6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
